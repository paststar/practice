# TODO
- [ ] Q) mask에서 값을 변경하는 방식으로 왜 할까?
- [ ] Q) pytroch gradient 정리 : 같은 layer를 여러번 사용하면 어떻게 되나?

- [ ] pytorch lighting(code style?)로 리팩토링
- [ ] model save
- [ ] model logging (wandb)
- [ ] ML test 코드
- [ ] GPT -  einsum ver 

- [ ] 모델 배포
- [ ] Nano GPT 참고
- [ ] tokenizer 변경 (ex. google-sentencepieice, openai-tiktoken)
- [ ] data loader 구현?

# Train data
- tiny shakespeare dataset
    ```
    wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -P data
    ```

# Reference
- https://www.youtube.com/watch?v=kCc8FmEb1nY
- https://github.com/karpathy/nanoGPT