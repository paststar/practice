{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor vs. torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : [1] new : tensor([1.])\n",
      "original : [2] new : tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "original_data = [1]\n",
    "#original_data = torch.Tensor([1])\n",
    "new_data = torch.Tensor(original_data)\n",
    "print(f\"original : {original_data} new : {new_data}\")\n",
    " \n",
    "# original data를 수정\n",
    "original_data[0] = 2\n",
    "print(f\"original : {original_data} new : {new_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : tensor([1]) new : tensor([1])\n",
      "original : tensor([2]) new : tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28900/1662099900.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_data = torch.tensor(original_data)\n"
     ]
    }
   ],
   "source": [
    "#original_data = [1]\n",
    "original_data = torch.tensor([1])\n",
    "new_data = torch.tensor(original_data)\n",
    "print(f\"original : {original_data} new : {new_data}\")\n",
    "\n",
    "# data를 수정하자\n",
    "original_data[0] = 2\n",
    "print(f\"original : {original_data} new : {new_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : tensor([1]) new : tensor([1])\n",
      "original : tensor([2]) new : tensor([2])\n"
     ]
    }
   ],
   "source": [
    "#original_data = [1]\n",
    "original_data = torch.tensor([1])\n",
    "new_data = torch.as_tensor(original_data)\n",
    "print(f\"original : {original_data} new : {new_data}\")\n",
    "\n",
    "# data를 수정하자\n",
    "original_data[0] = 2\n",
    "print(f\"original : {original_data} new : {new_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/pytorch_practice/UvA/tutorial2.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/UvA/tutorial2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m original_data \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/UvA/tutorial2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m new_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(original_data)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/UvA/tutorial2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moriginal : \u001b[39m\u001b[39m{\u001b[39;00moriginal_data\u001b[39m}\u001b[39;00m\u001b[39m new : \u001b[39m\u001b[39m{\u001b[39;00mnew_data\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/UvA/tutorial2.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# data를 수정하자\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got list)"
     ]
    }
   ],
   "source": [
    "original_data = [1]\n",
    "new_data = torch.from_numpy(original_data)\n",
    "print(f\"original : {original_data} new : {new_data}\")\n",
    "\n",
    "# data를 수정하자\n",
    "original_data[0] = 2\n",
    "print(f\"original : {original_data} new : {new_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't disable Kineto profiler when it's not running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/pytorch_practice/Docs + UvA/tensor.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m MAX_LEN \u001b[39m=\u001b[39m \u001b[39m100000\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m test_sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mfloat\u001b[39m(n) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(MAX_LEN)])\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m profiler\u001b[39m.\u001b[39mprofile(with_stack\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, profile_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m prof:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_TRIAL):\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mwith\u001b[39;00m profiler\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mTENSOR\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/profiler.py:305\u001b[0m, in \u001b[0;36mprofile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentered:\n\u001b[1;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mProfiler context manager is not reentrant\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_trace()\n\u001b[1;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_trace()\n\u001b[1;32m    307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/profiler.py:311\u001b[0m, in \u001b[0;36mprofile._prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    310\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     _prepare_profiler(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkineto_activities)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't disable Kineto profiler when it's not running"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "NUM_TRIAL = 100\n",
    "MAX_LEN = 100000\n",
    "\n",
    "test_sample = np.array([float(n) for n in range(MAX_LEN)])\n",
    "\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    for _ in range(NUM_TRIAL):\n",
    "        with profiler.record_function(\"TENSOR\"):\n",
    "            _ = torch.Tensor(test_sample)\n",
    "    \n",
    "    for _ in range(NUM_TRIAL):\n",
    "        with profiler.record_function(\"To_TENSOR\"):\n",
    "            _ =torch.tensor(test_sample)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- list/ndarry => tensor 속도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't disable Kineto profiler when it's not running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/pytorch_practice/Docs + UvA/tensor.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m test_sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mfloat\u001b[39m(n) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(MAX_LEN)])\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#test_sample = torch.tensor([float(n) for n in range(MAX_LEN)])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m profiler\u001b[39m.\u001b[39mprofile(with_stack\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, profile_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m prof:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_TRIAL):\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f74657374227d/root/pytorch_practice/Docs%20%2B%20UvA/tensor.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39mwith\u001b[39;00m profiler\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mLIST_AS_TENSOR\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/profiler.py:305\u001b[0m, in \u001b[0;36mprofile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentered:\n\u001b[1;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mProfiler context manager is not reentrant\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_trace()\n\u001b[1;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_trace()\n\u001b[1;32m    307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/profiler.py:311\u001b[0m, in \u001b[0;36mprofile._prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    310\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     _prepare_profiler(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkineto_activities)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't disable Kineto profiler when it's not running"
     ]
    }
   ],
   "source": [
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "NUM_TRIAL = 100\n",
    "MAX_LEN = 100000\n",
    "\n",
    "#test_sample = [float(n) for n in range(MAX_LEN)]\n",
    "test_sample = np.array([float(n) for n in range(MAX_LEN)])\n",
    "#test_sample = torch.tensor([float(n) for n in range(MAX_LEN)])\n",
    "\n",
    "with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "    for _ in range(NUM_TRIAL):\n",
    "        with profiler.record_function(\"AS_TENSOR\"):\n",
    "            _ = torch.as_tensor(test_sample)\n",
    "\n",
    "    for _ in range(NUM_TRIAL):\n",
    "        with profiler.record_function(\"LIST_TO_NUMPY_TO_TENSOR\"):\n",
    "            test_sample_np = np.asarray(test_sample)\n",
    "            _ = torch.from_numpy(test_sample_np)\n",
    "            #_ = torch.from_numpy(test_sample)\n",
    "    \n",
    "    for _ in range(NUM_TRIAL):\n",
    "        with profiler.record_function(\"To_TENSOR\"):\n",
    "            _ =torch.tensor(test_sample)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : tensor([1]) new : tensor([1], dtype=torch.int16)\n",
      "original : tensor([2]) new : tensor([1], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "original_data = torch.tensor([1])\n",
    "new_data = original_data.to(dtype=torch.int16)\n",
    "print(f\"original : {original_data} new : {new_data}\")\n",
    "\n",
    "# data를 수정하자\n",
    "original_data[0] = 2\n",
    "print(f\"original : {original_data} new : {new_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
